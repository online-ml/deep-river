{
  "Binary classification": {
    "Dataset": {
      "Bananas": "Bananas dataset.\n\nAn artificial dataset where instances belongs to several clusters with a banana shape.\nThere are two attributes that correspond to the x and y axis, respectively.\n\n    Name  Bananas                                                                                                        \n    Task  Binary classification                                                                                          \n Samples  5,300                                                                                                          \nFeatures  2                                                                                                              \n  Sparse  False                                                                                                          \n    Path  /Users/cedrickulbach/Documents/Projects/deep-river/.venv/lib/python3.10/site-packages/river/datasets/banana.zip",
      "Elec2": "Electricity prices in New South Wales.\n\nThis is a binary classification task, where the goal is to predict if the price of electricity\nwill go up or down.\n\nThis data was collected from the Australian New South Wales Electricity Market. In this market,\nprices are not fixed and are affected by demand and supply of the market. They are set every\nfive minutes. Electricity transfers to/from the neighboring state of Victoria were done to\nalleviate fluctuations.\n\n      Name  Elec2                                                      \n      Task  Binary classification                                      \n   Samples  45,312                                                     \n  Features  8                                                          \n    Sparse  False                                                      \n      Path  /Users/cedrickulbach/river_data/Elec2/electricity.csv      \n       URL  https://maxhalford.github.io/files/datasets/electricity.zip\n      Size  2.95 MiB                                                   \nDownloaded  True                                                       ",
      "Phishing": "Phishing websites.\n\nThis dataset contains features from web pages that are classified as phishing or not.\n\n    Name  Phishing                                                                                                            \n    Task  Binary classification                                                                                               \n Samples  1,250                                                                                                               \nFeatures  9                                                                                                                   \n  Sparse  False                                                                                                               \n    Path  /Users/cedrickulbach/Documents/Projects/deep-river/.venv/lib/python3.10/site-packages/river/datasets/phishing.csv.gz"
    },
    "Model": {
      "Logistic regression": "Pipeline (\n  StandardScaler (\n    with_std=True\n  ),\n  LogisticRegression (\n    optimizer=SGD (\n      lr=Constant (\n        learning_rate=0.005\n      )\n    )\n    loss=Log (\n      weight_pos=1.\n      weight_neg=1.\n    )\n    l2=0.\n    l1=0.\n    intercept_init=0.\n    intercept_lr=Constant (\n      learning_rate=0.01\n    )\n    clip_gradient=1e+12\n    initializer=Zeros ()\n  )\n)",
      "Deep River Logistic": "Pipeline (\n  StandardScaler (\n    with_std=True\n  ),\n  LogisticRegressionInitialized (\n    n_features=10\n    n_init_classes=2\n    loss_fn=\"cross_entropy\"\n    optimizer_fn=\"sgd\"\n    lr=0.005\n    output_is_logit=True\n    is_feature_incremental=True\n    is_class_incremental=True\n    device=\"cpu\"\n    seed=42\n    gradient_clip_value=None\n  )\n)",
      "Deep River MLP": "Pipeline (\n  StandardScaler (\n    with_std=True\n  ),\n  MultiLayerPerceptronInitialized (\n    n_features=10\n    n_width=5\n    n_layers=5\n    n_init_classes=2\n    loss_fn=\"cross_entropy\"\n    optimizer_fn=\"sgd\"\n    lr=0.005\n    output_is_logit=True\n    is_feature_incremental=True\n    is_class_incremental=True\n    device=\"cpu\"\n    seed=42\n    gradient_clip_value=None\n  )\n)",
      "Deep River LSTM": "Pipeline (\n  StandardScaler (\n    with_std=True\n  ),\n  LSTMClassifier (\n    n_features=10\n    hidden_size=32\n    n_init_classes=2\n    loss_fn=\"cross_entropy\"\n    optimizer_fn=\"adam\"\n    lr=0.001\n    output_is_logit=True\n    is_feature_incremental=True\n    is_class_incremental=True\n    device=\"cpu\"\n    seed=42\n    gradient_clip_value=None\n  )\n)",
      "Deep River RNN": "Pipeline (\n  StandardScaler (\n    with_std=True\n  ),\n  RNNClassifier (\n    n_features=10\n    hidden_size=32\n    num_layers=1\n    nonlinearity=\"tanh\"\n    n_init_classes=2\n    loss_fn=\"cross_entropy\"\n    optimizer_fn=\"adam\"\n    lr=0.001\n    output_is_logit=True\n    is_feature_incremental=True\n    is_class_incremental=True\n    device=\"cpu\"\n    seed=42\n    gradient_clip_value=None\n  )\n)",
      "[baseline] Prior class": "PriorClassifier ()"
    }
  },
  "Multiclass classification": {
    "Dataset": {
      "Hyperplane (limited 5000)": "Hyperplane(limited n=5000)",
      "LED (limited 5000)": "LED(limited n=5000)",
      "RandomRBF (limited 5000)": "RandomRBF(limited n=5000)"
    },
    "Model": {
      "Logistic regression": "Pipeline (\n  StandardScaler (\n    with_std=True\n  ),\n  LogisticRegression (\n    optimizer=SGD (\n      lr=Constant (\n        learning_rate=0.005\n      )\n    )\n    loss=Log (\n      weight_pos=1.\n      weight_neg=1.\n    )\n    l2=0.\n    l1=0.\n    intercept_init=0.\n    intercept_lr=Constant (\n      learning_rate=0.01\n    )\n    clip_gradient=1e+12\n    initializer=Zeros ()\n  )\n)",
      "Deep River Logistic": "Pipeline (\n  StandardScaler (\n    with_std=True\n  ),\n  LogisticRegressionInitialized (\n    n_features=10\n    n_init_classes=2\n    loss_fn=\"cross_entropy\"\n    optimizer_fn=\"sgd\"\n    lr=0.005\n    output_is_logit=True\n    is_feature_incremental=True\n    is_class_incremental=True\n    device=\"cpu\"\n    seed=42\n    gradient_clip_value=None\n  )\n)",
      "Deep River MLP": "Pipeline (\n  StandardScaler (\n    with_std=True\n  ),\n  MultiLayerPerceptronInitialized (\n    n_features=10\n    n_width=5\n    n_layers=5\n    n_init_classes=2\n    loss_fn=\"cross_entropy\"\n    optimizer_fn=\"sgd\"\n    lr=0.005\n    output_is_logit=True\n    is_feature_incremental=True\n    is_class_incremental=True\n    device=\"cpu\"\n    seed=42\n    gradient_clip_value=None\n  )\n)",
      "Deep River LSTM": "Pipeline (\n  StandardScaler (\n    with_std=True\n  ),\n  LSTMClassifier (\n    n_features=10\n    hidden_size=32\n    n_init_classes=2\n    loss_fn=\"cross_entropy\"\n    optimizer_fn=\"adam\"\n    lr=0.001\n    output_is_logit=True\n    is_feature_incremental=True\n    is_class_incremental=True\n    device=\"cpu\"\n    seed=42\n    gradient_clip_value=None\n  )\n)",
      "Deep River RNN": "Pipeline (\n  StandardScaler (\n    with_std=True\n  ),\n  RNNClassifier (\n    n_features=10\n    hidden_size=32\n    num_layers=1\n    nonlinearity=\"tanh\"\n    n_init_classes=2\n    loss_fn=\"cross_entropy\"\n    optimizer_fn=\"adam\"\n    lr=0.001\n    output_is_logit=True\n    is_feature_incremental=True\n    is_class_incremental=True\n    device=\"cpu\"\n    seed=42\n    gradient_clip_value=None\n  )\n)",
      "[baseline] Last Class": "NoChangeClassifier ()",
      "[baseline] Prior Class": "PriorClassifier ()"
    }
  },
  "Regression": {
    "Dataset": {
      "ChickWeights": "Chick weights along time.\n\nThe stream contains 578 items and 3 features. The goal is to predict the weight of each chick\nalong time, according to the diet the chick is on. The data is ordered by time and then by\nchick.\n\n    Name  ChickWeights                                                                                                          \n    Task  Regression                                                                                                            \n Samples  578                                                                                                                   \nFeatures  3                                                                                                                     \n  Sparse  False                                                                                                                 \n    Path  /Users/cedrickulbach/Documents/Projects/deep-river/.venv/lib/python3.10/site-packages/river/datasets/chick-weights.csv",
      "TrumpApproval": "Donald Trump approval ratings.\n\nThis dataset was obtained by reshaping the data used by FiveThirtyEight for analyzing Donald\nTrump's approval ratings. It contains 5 features, which are approval ratings collected by\n5 polling agencies. The target is the approval rating from FiveThirtyEight's model. The goal of\nthis task is to see if we can reproduce FiveThirtyEight's model.\n\n    Name  TrumpApproval                                                                                                             \n    Task  Regression                                                                                                                \n Samples  1,001                                                                                                                     \nFeatures  6                                                                                                                         \n  Sparse  False                                                                                                                     \n    Path  /Users/cedrickulbach/Documents/Projects/deep-river/.venv/lib/python3.10/site-packages/river/datasets/trump_approval.csv.gz"
    },
    "Model": {
      "Linear regression": "Pipeline (\n  StandardScaler (\n    with_std=True\n  ),\n  LinearRegression (\n    optimizer=SGD (\n      lr=Constant (\n        learning_rate=0.005\n      )\n    )\n    loss=Squared ()\n    l2=0.\n    l1=0.\n    intercept_init=0.\n    intercept_lr=Constant (\n      learning_rate=0.01\n    )\n    clip_gradient=1e+12\n    initializer=Zeros ()\n  )\n)",
      "Deep River Linear": "Pipeline (\n  StandardScaler (\n    with_std=True\n  ),\n  LinearRegressionInitialized (\n    n_features=10\n    loss_fn=\"mse\"\n    optimizer_fn=\"sgd\"\n    lr=0.005\n    is_feature_incremental=True\n    device=\"cpu\"\n    seed=42\n    gradient_clip_value=None\n  )\n)",
      "Deep River MLP": "Pipeline (\n  StandardScaler (\n    with_std=True\n  ),\n  MultiLayerPerceptron (\n    n_features=10\n    n_width=5\n    n_layers=5\n    loss_fn=\"mse\"\n    optimizer_fn=\"sgd\"\n    lr=0.005\n    is_feature_incremental=True\n    device=\"cpu\"\n    seed=42\n    gradient_clip_value=None\n  )\n)",
      "Deep River LSTM": "Pipeline (\n  StandardScaler (\n    with_std=True\n  ),\n  LSTMRegressor (\n    n_features=10\n    hidden_size=64\n    num_layers=1\n    dropout=0.1\n    gradient_clip_value=1.\n    loss_fn=\"mse\"\n    optimizer_fn=\"adam\"\n    lr=0.001\n    is_feature_incremental=True\n    device=\"cpu\"\n    seed=42\n  )\n)",
      "Deep River RNN": "Pipeline (\n  StandardScaler (\n    with_std=True\n  ),\n  RNNRegressor (\n    n_features=10\n    hidden_size=64\n    num_layers=1\n    nonlinearity=\"tanh\"\n    dropout=0.1\n    gradient_clip_value=1.\n    loss_fn=\"mse\"\n    optimizer_fn=\"adam\"\n    lr=0.001\n    is_feature_incremental=True\n    device=\"cpu\"\n    seed=42\n  )\n)",
      "River MLP": "Pipeline (\n  StandardScaler (\n    with_std=True\n  ),\n  MLPRegressor (\n    hidden_dims=(10,)\n    activations=(<class 'river.neural_net.activations.ReLU'>, <class 'river.neural_net.activations.ReLU'>, <class 'river.neural_net.activations.Identity'>)\n    loss=Squared ()\n    optimizer=SGD (\n      lr=Constant (\n        learning_rate=0.005\n      )\n    )\n    seed=42\n  )\n)",
      "[baseline] Mean predictor": "StatisticRegressor (\n  statistic=Mean ()\n)"
    }
  }
}